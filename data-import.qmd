# Data import {#sec-data-import}

```{r}
#| echo: false
source("_common.R")
```

Una vez recolectados los datos de diversas fuentes, el siguiente paso crucial
fue importarlos al entorno de trabajo donde se desarrolló el modelo analítico.
Para este propósito, se utilizó el lenguaje de programación R, aprovechando su
robusto ecosistema de bibliotecas y herramientas para el manejo de datos. En
particular, se empleó la biblioteca purrr para iterar sobre los conjuntos de
datos y cargarlos eficientemente en la memoria.

Se almacenaron tres tablas principales en el entorno de R: "diagnóstico",
"métricas" y "disponibilidad", que se asignaron a los objetos diag_00, metr_00
y disp_00, respectivamente. La importación de estos conjuntos de datos se
realizó en un solo ciclo utilizando la función `purrr::map()`, lo que permitió
una carga más rápida y eficiente de los datos en el entorno de trabajo. Este
enfoque no solo optimizó el tiempo de carga, sino que también facilitó la
posterior manipulación y análisis de los datos.

Este método de importación de datos aseguró que todas las tablas estuvieran
disponibles para el análisis subsiguiente, permitiendo una transición fluida
hacia las etapas de limpieza de datos y modelado.

```{r}
archivos <- dir_ls(type = "file", path = "data", glob = "*.csv")
```

```{r}
c(diag_00, disp_00, metr_00, lluv_00) %<-% (archivos |> map(read_csv))
```

```{r}
diag_00 |> glimpse(width = 70)
```

```{r}
metr_00 |> glimpse(width = 70)
```

```{r}
disp_00 |> glimpse(width = 70)
```

```{r}
lluv_00 |> glimpse(width = 70)
```

```{r}
#| eval: false
#| echo: false
write_fst(diag_00, path = "data/diag_00.fst", compress = 0)
write_fst(metr_00, path = "data/metr_00.fst", compress = 0)
write_fst(disp_00, path = "data/disp_00.fst", compress = 0)
write_fst(lluv_00, path = "data/lluv_00.fst", compress = 0)
```

