[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Close the Loop",
    "section": "",
    "text": "Preface\nEl proyecto busca desarrollar un modelo de machine learning para analizar y clasificar automáticamente las respuestas de las encuestas de NPS (Net Promoter Score) en Tigo Guatemala. El objetivo es utilizar estos insights para guiar decisiones estratégicas en áreas como inversión en infraestructura, optimización de red y mejora de la calidad del servicio. Al hacerlo, la empresa espera mejorar la percepción del cliente, medida a través del NPS, y en última instancia, aumentar la lealtad del cliente y el retorno de inversión (ROI)."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "En Tigo, medimos el Quality of Service (QoS) utilizando encuestas de Net Promoter Score (NPS) de tipo transaccional, las cuales evalúan la experiencia reciente del usuario con la calidad de nuestra red. Un día después de recibir las respuestas, un equipo de analistas, el Close The Loop, agrega un diagnóstico basado en métricas de red para representar la posible causa del Poor User Experience para cada cliente encuestado. Las posibles causas están categorizadas en: Capacidad, Cobertura, Optimización, Transmisión, Disponibilidad y No detractor.\nSe tiene un NPS Transaccional de red móvil que está impactando en el revenue y aumenta la taza de abandono de los clientes. Actualmente existe un equipo llamado CTL que analiza las encuestas y los KPIs de red con el fin de realizar una clasificación manual de los diagnósticos de los usuarios detractores de red. Posteriormente, se realizan acciones correctivas."
  },
  {
    "objectID": "data-adquisition.html",
    "href": "data-adquisition.html",
    "title": "Data adquisition",
    "section": "",
    "text": "La adquisición de datos, o Data Acquisition, es el proceso inicial y crítico en cualquier proyecto de machine learning o análisis de datos que implica recopilar, cargar y preparar datos para su posterior análisis. Esta fase es crucial porque los datos que se recojan determinarán la calidad del análisis y las conclusiones que se podrán obtener. Este proceso puede implicar múltiples etapas, desde la identificación de las fuentes de datos relevantes, pasando por la recopilación y el almacenamiento de los datos, hasta su importación al entorno de desarrollo para el análisis posterior."
  },
  {
    "objectID": "data-collection.html#diagnóstico",
    "href": "data-collection.html#diagnóstico",
    "title": "2  Data collection",
    "section": "2.1 Diagnóstico",
    "text": "2.1 Diagnóstico\nLa tabla maestra diagnóstico contiene…"
  },
  {
    "objectID": "data-collection.html#métricas",
    "href": "data-collection.html#métricas",
    "title": "2  Data collection",
    "section": "2.2 Métricas",
    "text": "2.2 Métricas\nLa tabla de métricas se caracteriza por …\nExisten métricas de tipo multicausalidad. Es posible que una métrica tenga efectos en múltiples categorías. Por ejemplo, un problema de optimización podría llevar a problemas de cobertura, y viceversa.\n\nthp_required_lte: Porcentaje de tiempo que mantiene el throughput requerido en LTE."
  },
  {
    "objectID": "data-collection.html#disponibilidad",
    "href": "data-collection.html#disponibilidad",
    "title": "2  Data collection",
    "section": "2.3 Disponibilidad",
    "text": "2.3 Disponibilidad\nCon esta disponibilidad lo que tenemos es principalmente…"
  },
  {
    "objectID": "data-import.html",
    "href": "data-import.html",
    "title": "3  Data import",
    "section": "",
    "text": "Una vez recolectados los datos de diversas fuentes, el siguiente paso crucial fue importarlos al entorno de trabajo donde se desarrolló el modelo analítico. Para este propósito, se utilizó el lenguaje de programación R, aprovechando su robusto ecosistema de bibliotecas y herramientas para el manejo de datos. En particular, se empleó la biblioteca purrr para iterar sobre los conjuntos de datos y cargarlos eficientemente en la memoria.\nSe almacenaron tres tablas principales en el entorno de R: “diagnóstico”, “métricas” y “disponibilidad”, que se asignaron a los objetos diag_00, metr_00 y disp_00, respectivamente. La importación de estos conjuntos de datos se realizó en un solo ciclo utilizando la función purrr::map(), lo que permitió una carga más rápida y eficiente de los datos en el entorno de trabajo. Este enfoque no solo optimizó el tiempo de carga, sino que también facilitó la posterior manipulación y análisis de los datos.\nEste método de importación de datos aseguró que todas las tablas estuvieran disponibles para el análisis subsiguiente, permitiendo una transición fluida hacia las etapas de limpieza de datos y modelado.\n\narchivos &lt;- dir_ls(type = \"file\", path = \"data\", glob = \"*.csv\")\n\n\nc(diag_00, disp_00, metr_00, lluv_00) %&lt;-% (archivos |&gt; map(read_csv))\n\n\ndiag_00 |&gt; glimpse(width = 70)\n#&gt; Rows: 72,644\n#&gt; Columns: 38\n#&gt; $ fct_srvy_dt         &lt;dbl&gt; 20220103, 20221026, 20221119, 20230614, …\n#&gt; $ bs_ln_cd            &lt;chr&gt; \"PRE\", \"HYB\", \"PRE\", \"PRE\", \"PRE\", \"HYB\"…\n#&gt; $ bs_ln_nm            &lt;chr&gt; \"PREPAID\", \"POSTPAID HYBRID\", \"PREPAID\",…\n#&gt; $ msisdn_dd           &lt;dbl&gt; 51684654, 50431166, 45707712, 37266836, …\n#&gt; $ srvy_id             &lt;dbl&gt; 539124531, 685399274, 698188789, 8119437…\n#&gt; $ nps_mdll            &lt;dbl&gt; 8, 10, 0, 10, 10, 10, 9, 5, 9, 9, 10, 10…\n#&gt; $ class_1             &lt;chr&gt; NA, NA, \"RENDIMIENTO\", NA, NA, NA, NA, \"…\n#&gt; $ class_2             &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ class_3             &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ users_class         &lt;dbl&gt; 0, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1,…\n#&gt; $ macro_desc          &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ class_desc          &lt;chr&gt; \"NEUTRO\", \"PROMOTOR\", \"DETRACTOR\", \"PROM…\n#&gt; $ bts_sh_nm_1         &lt;chr&gt; \"NBVP009C\", \"LGUA661B\", \"WGUA356A\", \"LSC…\n#&gt; $ trrtry_tf_nm        &lt;chr&gt; \"NOR-ORIENTE\", \"CENTRAL\", \"CENTRAL\", \"SU…\n#&gt; $ trrtry_cmrcl_nm     &lt;chr&gt; \"OCCIDENTE\", \"CENTRAL\", \"CENTRAL\", \"OCCI…\n#&gt; $ stt_nm              &lt;chr&gt; \"BAJA VERAPAZ\", \"GUATEMALA\", \"GUATEMALA\"…\n#&gt; $ cty_nm              &lt;chr&gt; \"CUBULCO\", \"AMATITLAN\", \"SAN JOSE PINULA…\n#&gt; $ segmento            &lt;chr&gt; \"TBD\", \"TBD\", \"TBD\", \"TBD\", \"TBD\", \"TBD\"…\n#&gt; $ tipo_cobertura      &lt;chr&gt; \"TBD\", \"TBD\", \"TBD\", \"TBD\", \"TBD\", \"TBD\"…\n#&gt; $ time_lte            &lt;dbl&gt; 0.9904817, 0.9884153, 0.0000000, 0.93261…\n#&gt; $ time_3g             &lt;dbl&gt; 0.004485764, 0.011045974, 0.987307939, 0…\n#&gt; $ cell_load_lte       &lt;dbl&gt; NA, 0.9655166, NA, 1.0000000, 0.2432869,…\n#&gt; $ cell_load_3g        &lt;dbl&gt; 1.00000000, 1.00000000, 1.00000000, 0.82…\n#&gt; $ thp_required_lte    &lt;dbl&gt; NA, 1.0000000, NA, 1.0000000, 0.3492566,…\n#&gt; $ thp_required_3g     &lt;dbl&gt; 1.00000000, 0.97479047, 0.99950695, 0.48…\n#&gt; $ prfrmnc             &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n#&gt; $ fct_dt              &lt;dbl&gt; 20230820, 20230820, 20230820, 20230820, …\n#&gt; $ fct_dt_ctl          &lt;date&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#&gt; $ msisdn_dd_ctl       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ srvy_id_ctl         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ cmmnt_clnt_1        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ cmmnt_clnt_2        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ diag                &lt;chr&gt; \"no_diag\", \"no_diag\", \"no_diag\", \"no_dia…\n#&gt; $ diag_dtl            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ cmmnt_anlyst        &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ cmnt_anlyst_on_clnt &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ month               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#&gt; $ rk                  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\n\nmetr_00 |&gt; glimpse(width = 70)\n#&gt; Rows: 273,434\n#&gt; Columns: 27\n#&gt; $ fct_srvy_dt            &lt;dbl&gt; 20220103, 20220105, 20220105, 2022010…\n#&gt; $ msisdn_dd              &lt;dbl&gt; 48752970, 46176730, 30484168, 4509420…\n#&gt; $ srvy_id                &lt;dbl&gt; 542177126, 543198907, 543386621, 5439…\n#&gt; $ r1                     &lt;dbl&gt; 1, 4, 3, 2, 1, 4, 2, 3, 2, 5, 5, 1, 3…\n#&gt; $ cll_prctg              &lt;dbl&gt; 0.824634392, 0.034284450, 0.151509464…\n#&gt; $ bts_sh_nm              &lt;chr&gt; \"LSMR065B\", \"5PTN071B\", \"KPTN639A\", \"…\n#&gt; $ rate_prb_dl            &lt;dbl&gt; 0.95210, 0.09452, 0.97424, 0.92788, 0…\n#&gt; $ cell_load              &lt;dbl&gt; 2.20687884, 0.10004342, 3.26123202, 0…\n#&gt; $ rrc_success_rate       &lt;dbl&gt; 0.9780692, 0.9967742, 0.9980931, 0.99…\n#&gt; $ erab_success_rate      &lt;dbl&gt; 0.9838215, 0.9984152, 0.9974223, 0.99…\n#&gt; $ service_drop_rate      &lt;dbl&gt; 0.008424494, 0.001610306, 0.001427862…\n#&gt; $ l_ul_interference_avg  &lt;dbl&gt; -114, -118, -119, -117, -117, -114, -…\n#&gt; $ thoughput_dl           &lt;dbl&gt; 806.6095, 12050.7719, 729.3367, 3163.…\n#&gt; $ thpughput_ul           &lt;dbl&gt; 157.78615, 52.38569, 184.64894, 1076.…\n#&gt; $ corrected_cqi          &lt;dbl&gt; 7, 9, 11, 10, 11, 9, 10, 0, 0, 11, 8,…\n#&gt; $ ra_ta_ue_index1        &lt;dbl&gt; 0.03724291, 0.14681440, 0.00000000, 0…\n#&gt; $ ra_ta_ue_index2        &lt;dbl&gt; 0.011535689, 0.101391650, 0.000000000…\n#&gt; $ ra_ta_ue_index3        &lt;dbl&gt; 0.057750188, 0.230932203, 0.000000000…\n#&gt; $ ra_ta_ue_index4        &lt;dbl&gt; 0.239936042, 0.414285714, 0.000093600…\n#&gt; $ ra_ta_ue_index5        &lt;dbl&gt; 0.296958855, 0.010638298, 0.081905479…\n#&gt; $ ra_ta_ue_index6        &lt;dbl&gt; 0.192351896, 0.019656020, 0.642143143…\n#&gt; $ ra_ta_ue_index7        &lt;dbl&gt; 0.129028815, 0.001472754, 0.276889244…\n#&gt; $ ra_ta_ue_total         &lt;dbl&gt; 9709, 470, 10736, 6225, 8972, 4737, 1…\n#&gt; $ volte_erlang           &lt;dbl&gt; 4.546555556, 0.006083333, 1.796555556…\n#&gt; $ modulation_64qam_ratio &lt;dbl&gt; 0.21873159, 0.46142123, 0.63927274, 0…\n#&gt; $ modulation_16qam_ratio &lt;dbl&gt; 0.32449740, 0.40558635, 0.26136434, 0…\n#&gt; $ modulation_qpsk_ratio  &lt;dbl&gt; 0.461401863, 0.107595772, 0.099906462…\n\n\ndisp_00 |&gt; glimpse(width = 70)\n#&gt; Rows: 72,426\n#&gt; Columns: 8\n#&gt; $ msisdn_dd             &lt;dbl&gt; 52079871, 59075914, 53184894, 40893852…\n#&gt; $ srvy_id               &lt;dbl&gt; 666820295, 636635685, 708482502, 54633…\n#&gt; $ time_cl               &lt;dbl&gt; 0.9567349, 0.9954649, 0.9949580, 0.481…\n#&gt; $ time_lte              &lt;dbl&gt; 0.9584363, 0.9730749, 0.9537411, 0.982…\n#&gt; $ time_thrgpt           &lt;dbl&gt; 0.8172875458, 0.6161637281, 0.63594658…\n#&gt; $ avlblty               &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ avlblty_tckt_2hrs     &lt;dbl&gt; 0.00000000, 0.00000000, 0.00000000, 0.…\n#&gt; $ unvlblty_ttl_hrs_prop &lt;dbl&gt; 13.0574712856, 14.2719810336, 4.607727…\n\n\nlluv_00 |&gt; glimpse(width = 70)\n#&gt; Rows: 348,785\n#&gt; Columns: 7\n#&gt; $ fct_srvy_dt      &lt;dbl&gt; 20221203, 20221203, 20221203, 20221203, 202…\n#&gt; $ fct_srvy_15_mnth &lt;dbl&gt; 20221101, 20221101, 20221101, 20221101, 202…\n#&gt; $ msisdn_dd        &lt;dbl&gt; 39015851, 39015851, 39015851, 39015851, 309…\n#&gt; $ srvy_id          &lt;dbl&gt; 705939618, 705939618, 705939618, 705939618,…\n#&gt; $ bts_sh_nm        &lt;chr&gt; \"LJLP277A\", \"LJLP933B\", \"LSRS693C\", \"OJLP27…\n#&gt; $ twr              &lt;chr&gt; \"JLP277\", \"JLP933\", \"SRS693\", \"JLP277\", \"SC…\n#&gt; $ rain             &lt;dbl&gt; 108, 88, 121, 108, 27, 15, 7, 15, 7, 4, 9, …"
  },
  {
    "objectID": "data-dictionary.html",
    "href": "data-dictionary.html",
    "title": "4  Data dictionary",
    "section": "",
    "text": "Table 4.1 muestra la primera parte del diccionario con los atributos del dataset que son generales\n\n\n\n\nTable 4.1: Features generales.\n\n\n\n\n\n\n\n\nfeature\ntipo_dato\ndescripcion\ntabla\n\n\n\n\ncll_prctg\ndouble\nPorcentaje de tiempo que estuvo conectado a la celda.\nMétricas\n\n\nfct_srvy_dt\ndate\nDía en que fue llenada la encuesta por el usuario\nDiagnóstico\n\n\nbts_sh_nm\ncharacter\nIdentificador de celda\nMétricas\n\n\nmsisdn_dd\ninteger\nNúmero de teléfono\nDiagnóstico\n\n\nsrvy_id\ninteger\nIdentificador de encuesta\nDiagnóstico\n\n\ncty_nm\ncharacter\nCiudad\nDiagnóstico\n\n\ntrrtry_cmrcl_nm\ncharacter\nRegión comercial\nDiagnóstico\n\n\ntrrtry_tf_nm\ncharacter\nRegión de RF planning\nDiagnóstico\n\n\nstt_nm\ncharacter\nDepartamento al que más se conecta\nDiagnóstico\n\n\ndiag\ncharacter\nVariable respuesta con las categorías a predecir\nDiagnóstico\n\n\n\n\n\n\nLa Table 4.2 muestra las métricas de red que están asociadas a las categorías de diagnóstico.\n\n\n\n\nTable 4.2: Métricas de red.\n\n\n\n\n\n\n\nfeature\ntipo_dato\ndescripcion\n\n\n\n\nrate_prb_dl\ndouble\nPorcentaje de uso de bloques de recursos en el enlace descendente.\n\n\nthroughput_dl\ndouble\nVelocidad de descarga por dispositivo en Mbps.\n\n\nthroughput_ul\ndouble\nVelocidad de subida por dispositivo en Mbps.\n\n\ntime_cl\ndouble\nPorcentaje de tiempo en buen estado de carga de celda.\n\n\nthp_required_lte\ndouble\nPorcentaje de tiempo con throughput requerido en LTE.\n\n\nra_ta_ue_index1\ndouble\nDistancia y conexiones a la estacion base (indice 1).\n\n\nra_ta_ue_index2\ndouble\nConexiones generadas a cierta distancia (Indice 2).\n\n\nra_ta_ue_index3\ndouble\nConexiones generadas a cierta distancia (Indice 3).\n\n\nra_ta_ue_index4\ndouble\nConexiones generadas a cierta distancia (Indice 4).\n\n\nra_ta_ue_index5\ndouble\nConexiones generadas a cierta distancia (Indice 5).\n\n\nra_ta_ue_index6\ndouble\nConexiones generadas a cierta distancia (Indice 6).\n\n\nra_ta_ue_index7\ndouble\nConexiones generadas a cierta distancia (Indice 7).\n\n\nra_ta_ue_total\ndouble\nTotal de conexiones de datos o llamadas.\n\n\ntime_lte\ndouble\nTiempo conectado a LTE.\n\n\navlblty\ndouble\nTiempo de navegacion sin fallas.\n\n\navlblty_tckt_2hrs\ndouble\nTickets de mas de 2 horas sobre total de tickets.\n\n\nunvlbty_ttl_hrs_prop\ndouble\nHoras de indisponibilidad del usuario.\n\n\nerab_success_rate\ndouble\nTasa de exito en la configuracion de E-RAB en LTE.\n\n\nrrc_success_rate\ndouble\nTasa de exito en la conexion RRC en LTE.\n\n\ncorrected_cqi\ndouble\nIndice de calidad de celda.\n\n\nl_ul_interference_avg\ndouble\nInterferencia promedio en el enlace ascendente.\n\n\nvolte_erlang\ndouble\nVolumen de trafico VoLTE en erlangs.\n\n\nmodulation_16qam_ratio\ndouble\nUso de modulacion 16QAM en la transferencia de datos.\n\n\nmodulation_64qam_ratio\ndouble\nUso de modulacion 64QAM en la transferencia de datos.\n\n\nmodulation_qpsk_ratio\ndouble\nUso de modulacion QPSK en la transferencia de datos.\n\n\n\n\n\n\n\n\n\n\nTable 4.3: Cantidad de precipitación.\n\n\n\n\n\n\n\n\nfeature\ntipo_dato\ndescripcion\ntabla\n\n\n\n\nfct_srvy_dt\ndate\nDía en que fue llenada la encuesta por el usuario\nDiagnóstico\n\n\nbts_sh_nm\ncharacter\nIdentificador de celda\nMétricas\n\n\nmsisdn_dd\ninteger\nNúmero de teléfono\nDiagnóstico\n\n\nsrvy_id\ninteger\nIdentificador de encuesta\nDiagnóstico\n\n\nrain\ndouble\nCantidad de lluvia en mm cúbicos\nDiagnóstico\n\n\n\n\n\n\nLa Table 4.3 muestra los \\(mm^{3}\\) promedio que cayeron sobre una celda específica."
  },
  {
    "objectID": "visualize.html",
    "href": "visualize.html",
    "title": "Visualize",
    "section": "",
    "text": "El objetivo clave en todo lo que hacemos en el proceso de modelado es encontrar formas fiables de explicar las variaciones en la variable respuesta. Encontrar patrones entre los predictores que se relacionan con la respuesta implica elegir un esquema de remuestreo para evitar el sobreajuste, seleccionar una métrica de rendimiento, ajustar y entrenar varios modelos, y comparar su desempeño para ver cuál es el mejor. Cuando tenemos un nuevo conjunto de datos, es fácil querer saltar directo al modelado predictivo para ver si logramos rápidamente un modelo que cumpla con las expectativas de rendimiento."
  },
  {
    "objectID": "data-prep.html#pre-selección-de-features",
    "href": "data-prep.html#pre-selección-de-features",
    "title": "5  Data prep",
    "section": "5.1 Pre-selección de features",
    "text": "5.1 Pre-selección de features\n\ncols_to_remove &lt;- c(\n \"tipo_cobertura\",   # 97.7% de los datos dicen TBD y el 2% es NA\n \"cell_load_3g\",     # André indica: \"mejor utilizar `cell_load_lte`\n \"users_class\",      # Ignorar por el momento\n \"fct_dt\",           # Actualización del registro a nivel de data\n \"time_3g\",          # Métrica vieja que ya no se le dio seguimiento\n \"bs_ln_nm\",         # Dejaremos `bs_ln_nm` por contener más información\n \"thp_required_3g\",  # Demasiados valores faltantes\n \"time_lte\",         # Demasiados valores faltantes,\n \"bs_ln_cd\",         # Feature no informativo\n \"nps_mdll\",         # Genera fuga de datos,\n \"bts_sh_nm_1\",      # Mejor usar bts_sh_nam\n \"cell_load_lte\"     # La métrica time_cl y time_lte son mejores\n )"
  },
  {
    "objectID": "data-prep.html#data-cleaning",
    "href": "data-prep.html#data-cleaning",
    "title": "5  Data prep",
    "section": "5.2 Data cleaning",
    "text": "5.2 Data cleaning\nA continuación se realiza la primera operación de impieza y transformación en el dataframe diag_00, almacenando el resultado en un nuevo dataframe llamado diag_01.\n\ndiag_01 &lt;- diag_00 |&gt;\n select(\n  where(\n1   \\(x) length(unique(x)) != 1 &&\n2   mean(is.na(x)) &lt; 0.5),\n3  -all_of(cols_to_remove)\n ) |&gt;\n mutate(\n4  across(fct_srvy_dt, \\(fecha) ymd(fecha)),\n5  across(where(is.character), \\(col) estandarizar_columnas(col)),\n  across(msisdn_dd:srvy_id, as.integer)\n ) |&gt;\n relocate(fct_srvy_dt, msisdn_dd, srvy_id)\n\n\n1\n\nQuitar columnas que tengan un solo valor único (constante).\n\n2\n\nQuitar columnas que tengan más del 50% de valores perdidos (NA).\n\n3\n\nEliminar columnas innecesarias validadas por el equipo de CTL (Close The Loop).\n\n4\n\nConvertir la columna fct_srvy_dt a tipo fecha.\n\n5\n\nLa función estandarizar_columnas() convierte a mayúscula y elimina espacios en blanco."
  },
  {
    "objectID": "data-prep.html#centinelas",
    "href": "data-prep.html#centinelas",
    "title": "5  Data prep",
    "section": "5.3 Centinelas",
    "text": "5.3 Centinelas\nUn valor centinela es un valor especial en el contexto de programación y análisis de datos que se utiliza para indicar una condición como un error, un valor no definido, el final de una lista, entre otros. En el análisis de datos, los valores centinela suelen ser cadenas de texto como “NA”, “TBD” (To Be Determined), “UNKNOWN”, etc., que no tienen un significado numérico pero sirven para indicar que la información no está disponible o aún no se ha decidido.\n\n\n\n\nTable 5.1: Cantidad de centinelas.\n\n\nfeature\ntbds\n\n\n\n\ntrrtry_tf_nm\n3014\n\n\ntrrtry_cmrcl_nm\n3014\n\n\ncty_nm\n451\n\n\nstt_nm\n12\n\n\nclass_desc\n0\n\n\ndiag\n0\n\n\n\n\n\n\nA continuación, realizaremos el reemplazo de los valores centinelas identificados, completando con esta operación la codificación explícita de los mismos en valores perdidos o NAs\n\ndiag_02 &lt;- diag_01 |&gt;\n arrange(fct_srvy_dt, msisdn_dd, srvy_id) |&gt;\n mutate(\n  across(where(is.character), \\(x) na_if(x, \"TBD\")),\n  across(where(is.character), \\(x) na_if(x, \"TO_BE_DETERMINED\")))\n\n\n\n\n\nTable 5.2: Centinelas restantes.\n\n\nfeature\ntbds\n\n\n\n\nclass_desc\n0\n\n\ntrrtry_tf_nm\n0\n\n\ntrrtry_cmrcl_nm\n0\n\n\nstt_nm\n0\n\n\ncty_nm\n0\n\n\ndiag\n0\n\n\n\n\n\n\nEn la tabla Table 5.2 vemos que se han reemplazado correctamente todos los los valores centinelas."
  },
  {
    "objectID": "data-prep.html#colapso-respuesta",
    "href": "data-prep.html#colapso-respuesta",
    "title": "5  Data prep",
    "section": "5.4 Colapso respuesta",
    "text": "5.4 Colapso respuesta\n\n\nMostrar Código\ndiag_02 |&gt;\n tabyl(diag) |&gt;\n arrange(desc(n)) |&gt;\n adorn_pct_formatting() |&gt; \n gt() |&gt; \n gt_theme_538() |&gt; \n cols_align(align = \"center\", columns = where(~ is.numeric(.x)))\n\n\n\n\n\nTable 5.3:  Categorías Iniciales \n  \n    \n    \n      diag\n      n\n      percent\n    \n  \n  \n    NO_DIAG\n64588\n88.9%\n    CAPACIDAD\n2108\n2.9%\n    OPTIMIZACION\n1322\n1.8%\n    DISPONIBILIDAD\n989\n1.4%\n    COBERTURA\n987\n1.4%\n    NO_TECNICO\n830\n1.1%\n    TRANSMISION\n663\n0.9%\n    HOME\n352\n0.5%\n    FORCING\n282\n0.4%\n    ENCUESTA\n252\n0.3%\n    EQUIPO\n241\n0.3%\n    OTROS_TECNICOS\n30\n0.0%\n  \n  \n  \n\n\n\n\n\nSe observa en la tabla Table 5.3 las categorías iniciales con las que cuenta el set de datos.\n\n\nCódigo\ndiag_02 |&gt;\n filter(diag == \"NO_DIAG\") |&gt;\n barra(x = class_desc) +\n theme(legend.position = \"none\") +\n labs(title = \"Class Description en etiqueta no-diag\")\n\n\n\n\n\nFigure 5.1: Distribución de las clases en categoría NO-DIAG\n\n\n\n\nEn la figura Figure 5.1 se ve que la la clase predominante llamada NO_DIAG presenta una distribución de descripción de clases en la que los promotores son la mayoría. Es importante entonces, con el fin de poder contar con una clase que genere el mayor contraste posible con las categoría de diagnóstico de detractores, seleccionar únicamente promotores para esta clase.\nDefinamos entonces las categorías de diagnóstico que quedarán finalmente. La selección se realizó con base a la cantidad de observaciones disponibles.\n\netiquetas &lt;- c(\n \"CAPACIDAD\",\n \"OPTIMIZACION\",\n \"COBERTURA\",\n \"DISPONIBILIDAD\",\n \"NO_DIAG\")\n\n\nset.seed(2023)\n\n\ndiag_03 &lt;- diag_02 |&gt;\n1 filter(diag %in% etiquetas) |&gt;\n2 split(~ diag) |&gt;\n3 map_at(\"NO_DIAG\", \\(df) df |&gt;\n4  filter(class_desc == \"PROMOTOR\") |&gt;\n5  drop_na() |&gt;\n6  slice_sample(n = 1800) |&gt;\n7  distinct(msisdn_dd, .keep_all = TRUE)) |&gt;\n8 list_rbind() |&gt;\n mutate(\n across(diag,\n9  \\(x) case_match(x, \"NO_DIAG\" ~ \"PROMOTOR\", .default = diag))) |&gt;\n10 select(-class_desc) |&gt;\n11 distinct(msisdn_dd, .keep_all = TRUE)\n\n\n1\n\nDejar únicamente las etiquetas seleccionadas por los SME\n\n2\n\nDividir el dataframe en una lista de dataframes según los valores únicos de la columna diag\n\n3\n\nModificar únicamente el datraframe de la lista que contiene la etiqueta NO_DIAG.\n\n4\n\nAplicar un filtro al dataframe NO_DIAG para que solo queden los promotores.\n\n5\n\nEliminar todos los valores perdidos de este dataframe.\n\n6\n\nTomar una muestra aleatoria de 1800 observaciones.\n\n7\n\nGarantizar que solo queden usuarios únicos con una sola encuesta.\n\n8\n\nUnir la lista en un único dataframe\n\n9\n\nCambiar la etiqueta NO_DIAG por PROMOTOR.\n\n10\n\nRemover la columna class_desc ya que puede causar data leakage.\n\n11\n\nRemover duplicados, dejando únicamente un usuario.\n\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\nEn la etapa de segmentación de datos en conjuntos de entrenamiento, validación y prueba, así como durante la validación cruzada, se presentan complicaciones si un usuario individual (identificado por msisdn_dd) posee múltiples categorías en la variable diag. Para llevar a cabo una estratificación precisa, es esencial que cada valor único de la unidad experimental (en este contexto, el usuario o msisdn_dd) tenga asignado un único valor en la variable diag. Si esta condición no se satisface, se producirá un error en las tareas de segmentación y validación cruzada."
  },
  {
    "objectID": "data-prep.html#métricas",
    "href": "data-prep.html#métricas",
    "title": "5  Data prep",
    "section": "5.5 Métricas",
    "text": "5.5 Métricas\n\nmetr_01 &lt;- metr_00 |&gt;\n mutate(across(fct_srvy_dt, ymd)) |&gt;\n relocate(fct_srvy_dt, msisdn_dd, srvy_id, r1, bts_sh_nm) |&gt;\n arrange(fct_srvy_dt, msisdn_dd) |&gt;\n select(-c(cell_load, service_drop_rate))"
  },
  {
    "objectID": "data-prep.html#disponibilidad",
    "href": "data-prep.html#disponibilidad",
    "title": "5  Data prep",
    "section": "5.6 Disponibilidad",
    "text": "5.6 Disponibilidad\nLa tabla disponibilidad contiene valores negativos, los cuales son incorrectos para estas métricas. Es necesario convertir estos valores a NA de manera explícita.\n\ndisp_01 &lt;- disp_00 |&gt; \n mutate(across(everything(), \\(x) na_if(x, -1))) |&gt; \n select(-time_thrgpt)"
  },
  {
    "objectID": "data-prep.html#precipitación",
    "href": "data-prep.html#precipitación",
    "title": "5  Data prep",
    "section": "5.7 Precipitación",
    "text": "5.7 Precipitación\nLa columna fct_srvy_15_mnt es una columna que se utilizó en el ETL para poder calcular el mes al que debía asociar la precipitación promedio. En este momento ya no es relevante para el análisis, por lo que se debe eliminar. Se aprovecha para poder convertir la variable fct_srvy_dt en tipo fecha.\n\nlluv_01 &lt;- lluv_00 |&gt;\n select(-fct_srvy_15_mnth) |&gt; \n mutate(across(fct_srvy_dt, ymd))"
  },
  {
    "objectID": "data-prep.html#unión",
    "href": "data-prep.html#unión",
    "title": "5  Data prep",
    "section": "5.8 Unión",
    "text": "5.8 Unión\nPara la unión utilizaremos una llave compuesta por el número de teléfono del usuario representado por la variable msisdn_dd y el número de encuesta srvy_id.\nLa primera unión a realizar es entre las métricas de red, disponibilidad y cantidad de precipitación promedio.\n\n# ctl_00 solo disp_00: 273,434 x30\nctl_00 &lt;- metr_01 |&gt;\n inner_join(disp_01, join_by(msisdn_dd, srvy_id)) |&gt; \n inner_join(lluv_01, join_by(msisdn_dd, srvy_id, fct_srvy_dt, bts_sh_nm))\n\nLa siguiente unión será contra la tabla maestra diag_03. Posteriormente aplicaremos transformaciones relacionadas a la posición de las columnas y convertir a tipo entero las variables identificadoras.\n\n# 26,559 x 35\nctl_01 &lt;- diag_03 |&gt;\n inner_join(ctl_00, join_by(msisdn_dd, srvy_id, fct_srvy_dt)) |&gt;\n relocate(diag, .after = last_col()) |&gt;\n select(-r1) |&gt;\n mutate(across(c(msisdn_dd, srvy_id), as.integer))\n\nSe completó el proceso de limpieza, transformación y data blending inicial. En la siguiente sección, se procederá a realizar la división de los datos para poder proseguir con el EDA."
  },
  {
    "objectID": "split.html#snooping-bias",
    "href": "split.html#snooping-bias",
    "title": "6  Split",
    "section": "6.1 Snooping bias",
    "text": "6.1 Snooping bias\nPara evitar el snooping bias es necesario poder dividir el conjunto total en tres partes: entrenamiento, validación y prueba. Esto se debe a que si se realiza el EDA con todos los datos, se corre el riesgo de que esto influya en la selección de los modelos. Las vistas preliminares de la sección anterior no generan problemas, sin embargo es importante asegurarse de que cualquier decisión que tomemos se base únicamente en lo visto en el conjunto de entrenamiento (Géron 2017)"
  },
  {
    "objectID": "split.html#data-spending",
    "href": "split.html#data-spending",
    "title": "6  Split",
    "section": "6.2 Data spending",
    "text": "6.2 Data spending\nEn el contexto del análisis de datos utilizando métodos de resampling agrupados, como group_initial_validation_split en el paquete rsample, se asume que todas las observaciones dentro de un grupo son interdependientes y comparten características similares. Por lo tanto, se requiere que cada unidad experimental y de agrupamiento, en este caso, cada usuario, tenga un único valor para la variable de estratificación, en este caso, el diagnóstico. La presencia de múltiples valores de diagnóstico para un solo usuario violaría la suposición de homogeneidad dentro del grupo, lo cual podría llevar a estimaciones sesgadas y resultados poco fiables en el análisis posterior. Además, la interpretación de los resultados y la aplicabilidad del modelo podrían verse complicadas. Por lo tanto, se establece que la homogeneidad dentro de cada grupo es esencial para mantener la integridad del análisis y la validez de los resultados.\nSe debe validar que los datos contienen un valor único en diag para cada usuario msisdn_nd\n\nctl_01 |&gt; \n summarise(distintos = n_distinct(srvy_id), .by = msisdn_dd) |&gt; \n filter(distintos &gt; 1)\n#&gt; # A tibble: 0 × 2\n#&gt; # ℹ 2 variables: msisdn_dd &lt;int&gt;, distintos &lt;int&gt;\n\nLa validación indica que hay un solo diagnóstico por usuario.\nCon la función group_initial_validation_split() se creará una división triple de los datos en un conjunto de entrenamiento, validación y prueba. Se realizará estratificación sobre nuestra variable objetivo diag. Dejaremos las proporciones por defecto debido a que tenemos 24742 observaciones. El valor predeterminado de prop = c(0.6, 0.2) lo que significa que el 60% de los datos se asignarán al conjunto de entrenamiento, un 20% a validación y el 20% restante al conjunto de prueba.\n\nctl_split &lt;- ctl_01 |&gt; \n group_initial_validation_split(group = msisdn_dd, strata = diag)\n\n\nctl_split\n#&gt; &lt;Training/Validation/Testing/Total&gt;\n#&gt; &lt;14850/4943/4949/24742&gt;\n\n\n\nCode\nlist(train = training(ctl_split), \n     validation = validation(ctl_split), \n     test = testing(ctl_split)) |&gt; \n map(\\(x) nrow(x)) |&gt; \n as_tibble() |&gt; \n pivot_longer(cols = everything(), \n              names_to = \"division\", values_to = \"observaciones\") |&gt; \n mutate(prop = observaciones / sum(observaciones)) |&gt; \n gt() |&gt; \n tab_header(\n    title = md(\"**Three-Way Split**\"),\n    subtitle = md(\"Distribución basada en la cantidad disponible de datos\")\n  ) |&gt; \n gt_theme_538() |&gt; \n fmt_number(columns = observaciones, decimals = 0) |&gt; \n fmt_percent(\n    columns = prop,\n    decimals = 1\n  )\n\n\n\n\n\n  \n    \n      Three-Way Split\n    \n    \n      Distribución basada en la cantidad disponible de datos\n    \n    \n      division\n      observaciones\n      prop\n    \n  \n  \n    train\n14,850\n60.0%\n    validation\n4,943\n20.0%\n    test\n4,949\n20.0%\n  \n  \n  \n\n\n\n\nEn la tabla anterior se observa como quedó la distribución.\nPodemos acceder a estos conjuntos de la siguiente manera:\n\ntraining(ctl_split) |&gt; \n head()\n#&gt; # A tibble: 6 × 37\n#&gt;   fct_srvy_dt msisdn_dd   srvy_id trrtry_tf_nm  trrtry_cmrcl_nm stt_nm    cty_nm\n#&gt;   &lt;date&gt;          &lt;int&gt;     &lt;int&gt; &lt;chr&gt;         &lt;chr&gt;           &lt;chr&gt;     &lt;chr&gt; \n#&gt; 1 2022-01-03   45392596 542205822 NOR_ORIENTE   OCCIDENTE       ALTA_VER… SAN_J…\n#&gt; 2 2022-01-03   45392596 542205822 NOR_ORIENTE   OCCIDENTE       ALTA_VER… SAN_J…\n#&gt; 3 2022-01-03   45392596 542205822 NOR_ORIENTE   OCCIDENTE       ALTA_VER… SAN_J…\n#&gt; 4 2022-01-03   46184079 542208786 NOR_OCCIDENTE OCCIDENTE       TOTONICA… SAN_B…\n#&gt; 5 2022-01-03   46184079 542208786 NOR_OCCIDENTE OCCIDENTE       TOTONICA… SAN_B…\n#&gt; 6 2022-01-03   46184079 542208786 NOR_OCCIDENTE OCCIDENTE       TOTONICA… SAN_B…\n#&gt; # ℹ 30 more variables: thp_required_lte &lt;dbl&gt;, bts_sh_nm &lt;chr&gt;,\n#&gt; #   cll_prctg &lt;dbl&gt;, rate_prb_dl &lt;dbl&gt;, rrc_success_rate &lt;dbl&gt;,\n#&gt; #   erab_success_rate &lt;dbl&gt;, l_ul_interference_avg &lt;dbl&gt;, thoughput_dl &lt;dbl&gt;,\n#&gt; #   thpughput_ul &lt;dbl&gt;, corrected_cqi &lt;dbl&gt;, ra_ta_ue_index1 &lt;dbl&gt;,\n#&gt; #   ra_ta_ue_index2 &lt;dbl&gt;, ra_ta_ue_index3 &lt;dbl&gt;, ra_ta_ue_index4 &lt;dbl&gt;,\n#&gt; #   ra_ta_ue_index5 &lt;dbl&gt;, ra_ta_ue_index6 &lt;dbl&gt;, ra_ta_ue_index7 &lt;dbl&gt;,\n#&gt; #   ra_ta_ue_total &lt;dbl&gt;, volte_erlang &lt;dbl&gt;, modulation_64qam_ratio &lt;dbl&gt;, …\n\n\n\n\n\nGéron, Aurélien. 2017. Hands-on Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. First edition. Beijing ; Boston: O’Reilly Media."
  },
  {
    "objectID": "eda.html#estructura",
    "href": "eda.html#estructura",
    "title": "7  EDA",
    "section": "7.1 Estructura",
    "text": "7.1 Estructura\nEl proceso de preparación y limpieza dió como resultado un único set de datos, el cual consta de 14850 filas y 37 columnas.\n\nctl_train |&gt; glimpse(width = 71)\n#&gt; Rows: 14,850\n#&gt; Columns: 37\n#&gt; $ fct_srvy_dt            &lt;date&gt; 2022-01-03, 2022-01-03, 2022-01-03, 2…\n#&gt; $ msisdn_dd              &lt;int&gt; 45392596, 45392596, 45392596, 46184079…\n#&gt; $ srvy_id                &lt;int&gt; 542205822, 542205822, 542205822, 54220…\n#&gt; $ trrtry_tf_nm           &lt;chr&gt; \"NOR_ORIENTE\", \"NOR_ORIENTE\", \"NOR_ORI…\n#&gt; $ trrtry_cmrcl_nm        &lt;chr&gt; \"OCCIDENTE\", \"OCCIDENTE\", \"OCCIDENTE\",…\n#&gt; $ stt_nm                 &lt;chr&gt; \"ALTA_VERAPAZ\", \"ALTA_VERAPAZ\", \"ALTA_…\n#&gt; $ cty_nm                 &lt;chr&gt; \"SAN_JUAN_CHAMELCO\", \"SAN_JUAN_CHAMELC…\n#&gt; $ thp_required_lte       &lt;dbl&gt; 1.0000000, 1.0000000, 1.0000000, NA, N…\n#&gt; $ bts_sh_nm              &lt;chr&gt; \"LAVP527D\", \"LAVP137C\", \"HAVP527G\", \"L…\n#&gt; $ cll_prctg              &lt;dbl&gt; 0.08431669, 0.38918104, 0.16295014, 0.…\n#&gt; $ rate_prb_dl            &lt;dbl&gt; 0.88582, 0.73678, 0.88838, 0.96468, 0.…\n#&gt; $ rrc_success_rate       &lt;dbl&gt; 0.9986484, 0.9981464, 0.9980925, 0.999…\n#&gt; $ erab_success_rate      &lt;dbl&gt; 0.9985284, 0.9979743, 0.9984071, 0.999…\n#&gt; $ l_ul_interference_avg  &lt;dbl&gt; -114, -114, -117, -108, -114, -112, -1…\n#&gt; $ thoughput_dl           &lt;dbl&gt; 862.1951, 4133.4229, 1889.2004, 648.11…\n#&gt; $ thpughput_ul           &lt;dbl&gt; 1434.3077, 930.9678, 375.1958, 531.528…\n#&gt; $ corrected_cqi          &lt;dbl&gt; 9, 8, 10, 12, 7, 6, 8, 7, 0, 10, 8, 9,…\n#&gt; $ ra_ta_ue_index1        &lt;dbl&gt; 0.021427501, 0.248430081, 0.013204537,…\n#&gt; $ ra_ta_ue_index2        &lt;dbl&gt; 0.260526478, 0.191786533, 0.141878047,…\n#&gt; $ ra_ta_ue_index3        &lt;dbl&gt; 0.616793046, 0.345042395, 0.502266308,…\n#&gt; $ ra_ta_ue_index4        &lt;dbl&gt; 0.07730710, 0.04562579, 0.28956185, 0.…\n#&gt; $ ra_ta_ue_index5        &lt;dbl&gt; 0.008302583, 0.137567053, 0.047603062,…\n#&gt; $ ra_ta_ue_index6        &lt;dbl&gt; 0.000661000, 0.004699078, 0.000000000,…\n#&gt; $ ra_ta_ue_index7        &lt;dbl&gt; 0.000127000, 0.000000000, 0.000000000,…\n#&gt; $ ra_ta_ue_total         &lt;dbl&gt; 20596, 5135, 14391, 55033, 6774, 3478,…\n#&gt; $ volte_erlang           &lt;dbl&gt; 30.1669444, 3.4219444, 2.0346667, 28.9…\n#&gt; $ modulation_64qam_ratio &lt;dbl&gt; 0.42234061, 0.32748105, 0.63852959, 0.…\n#&gt; $ modulation_16qam_ratio &lt;dbl&gt; 0.4288202, 0.4107964, 0.2978861, 0.169…\n#&gt; $ modulation_qpsk_ratio  &lt;dbl&gt; 0.15673500, 0.26979092, 0.06972546, 0.…\n#&gt; $ time_cl                &lt;dbl&gt; 0.9203436, 0.9203436, 0.9203436, 0.578…\n#&gt; $ time_lte               &lt;dbl&gt; 0.9847598, 0.9847598, 0.9847598, 0.958…\n#&gt; $ avlblty                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#&gt; $ avlblty_tckt_2hrs      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n#&gt; $ unvlblty_ttl_hrs_prop  &lt;dbl&gt; 0.000000000, 0.000000000, 0.000000000,…\n#&gt; $ twr                    &lt;chr&gt; \"AVP527\", \"AVP137\", \"AVP527\", \"HHT174\"…\n#&gt; $ rain                   &lt;dbl&gt; 215, 215, 215, 11, 10, 10, 11, 6, 320,…\n#&gt; $ diag                   &lt;chr&gt; \"CAPACIDAD\", \"CAPACIDAD\", \"CAPACIDAD\",…\n\n\n\nMostrar Código\nctl_train |&gt; \n slice_head(n = 5) |&gt; \n gt() |&gt; \n tab_header(\n    title = md(\"**Muestra Aleatoria - CTL**\"),\n    subtitle = md(\"Tabla principal\")\n  ) |&gt; \n gt_theme_538() |&gt; \n fmt_number(columns = cll_prctg:last_col(), decimals = 2) |&gt; \n cols_align_decimal() |&gt; \n cols_align(align = \"center\", columns = where(~ is.numeric(.x))) |&gt; \n tab_footnote(\n  footnote = md(\"Cada usuario tiene el top 5 celdas a las que más se conecta\"),\n  locations = cells_body(columns = bts_sh_nm, rows = 1)) \n\n\n\n\n\nTable 7.1:  ctl \n  \n    \n      Muestra Aleatoria - CTL\n    \n    \n      Tabla principal\n    \n    \n      fct_srvy_dt\n      msisdn_dd\n      srvy_id\n      trrtry_tf_nm\n      trrtry_cmrcl_nm\n      stt_nm\n      cty_nm\n      thp_required_lte\n      bts_sh_nm\n      cll_prctg\n      rate_prb_dl\n      rrc_success_rate\n      erab_success_rate\n      l_ul_interference_avg\n      thoughput_dl\n      thpughput_ul\n      corrected_cqi\n      ra_ta_ue_index1\n      ra_ta_ue_index2\n      ra_ta_ue_index3\n      ra_ta_ue_index4\n      ra_ta_ue_index5\n      ra_ta_ue_index6\n      ra_ta_ue_index7\n      ra_ta_ue_total\n      volte_erlang\n      modulation_64qam_ratio\n      modulation_16qam_ratio\n      modulation_qpsk_ratio\n      time_cl\n      time_lte\n      avlblty\n      avlblty_tckt_2hrs\n      unvlblty_ttl_hrs_prop\n      twr\n      rain\n      diag\n    \n  \n  \n    2022-01-03\n45392596 \n542205822 \nNOR_ORIENTE\nOCCIDENTE\nALTA_VERAPAZ\nSAN_JUAN_CHAMELCO\n1 \nLAVP527D1\n0.08\n0.89\n1.00\n1.00\n−114.00\n  862.20\n1,434.31\n 9.00\n0.02\n0.26\n0.62\n0.08\n0.01\n0.00\n0.00\n20,596.00\n30.17\n0.42\n0.43\n0.16\n0.92\n0.98\n1.00\n0.00\n0.00\nAVP527\n215.00\nCAPACIDAD\n    2022-01-03\n45392596 \n542205822 \nNOR_ORIENTE\nOCCIDENTE\nALTA_VERAPAZ\nSAN_JUAN_CHAMELCO\n1 \nLAVP137C\n0.39\n0.74\n1.00\n1.00\n−114.00\n4,133.42\n  930.97\n 8.00\n0.25\n0.19\n0.35\n0.05\n0.14\n0.00\n0.00\n 5,135.00\n 3.42\n0.33\n0.41\n0.27\n0.92\n0.98\n1.00\n0.00\n0.00\nAVP137\n215.00\nCAPACIDAD\n    2022-01-03\n45392596 \n542205822 \nNOR_ORIENTE\nOCCIDENTE\nALTA_VERAPAZ\nSAN_JUAN_CHAMELCO\n1 \nHAVP527G\n0.16\n0.89\n1.00\n1.00\n−117.00\n1,889.20\n  375.20\n10.00\n0.01\n0.14\n0.50\n0.29\n0.05\n0.00\n0.00\n14,391.00\n 2.03\n0.64\n0.30\n0.07\n0.92\n0.98\n1.00\n0.00\n0.00\nAVP527\n215.00\nCAPACIDAD\n    2022-01-03\n46184079 \n542208786 \nNOR_OCCIDENTE\nOCCIDENTE\nTOTONICAPAN\nSAN_BARTOLO\nNA\nLHHT174B\n0.08\n0.96\n1.00\n1.00\n−108.00\n  648.12\n  531.53\n12.00\n0.22\n0.57\n0.17\n0.01\n0.00\n0.00\n0.00\n55,033.00\n28.97\n0.78\n0.17\n0.05\n0.58\n0.96\n1.00\n0.00\n0.00\nHHT174\n 11.00\nCAPACIDAD\n    2022-01-03\n46184079 \n542208786 \nNOR_OCCIDENTE\nOCCIDENTE\nTOTONICAPAN\nSAN_BARTOLO\nNA\nHTTN804E\n0.27\n0.88\n1.00\n1.00\n−114.00\n1,199.46\n  376.57\n 7.00\n0.01\n0.03\n0.02\n0.13\n0.45\n0.36\n0.00\n 6,774.00\n 0.11\n0.16\n0.37\n0.47\n0.58\n0.96\n1.00\n0.00\n0.00\nTTN804\n 10.00\nCAPACIDAD\n  \n  \n  \n    \n      1 Cada usuario tiene el top 5 celdas a las que más se conecta\n    \n  \n\n\n\n\n\n\n\nCódigo\nplot_intro(\n ctl_train,ggtheme = yunkel,\n title = \"Resumen Descriptivo\",\n geom_label_args = list(label.size = 0.8, size = 7),\n theme_config = list(\n axis.text = element_text(size = 40)))\n\n\n\n\n\nFigure 7.1: Se puede apreciar que la gran mayoría de las columnas están completas. Un 80% son features de tipo continuo y el restante son de tipo categórico. Se requiere explorar los valores faltantes con mayor detalle."
  },
  {
    "objectID": "eda.html#sec-mr",
    "href": "eda.html#sec-mr",
    "title": "7  EDA",
    "section": "7.2 Medidas repetidas",
    "text": "7.2 Medidas repetidas\n\n\nCódigo\nctl_train |&gt;\n get_dupes(msisdn_dd) |&gt; \n head(5) |&gt; \n select(\n  fct_srvy_dt, msisdn_dd, srvy_id, bts_sh_nm) |&gt; \n gt() |&gt; \n tab_header(\n  title = md(\"**Datos de Perfil**\"),\n    subtitle = md(\"Medidas repetidas\")\n  ) |&gt; \n gt_theme_538()\n\n\n\n\n\nTable 7.2:  Valores repetidos \n  \n    \n      Datos de Perfil\n    \n    \n      Medidas repetidas\n    \n    \n      fct_srvy_dt\n      msisdn_dd\n      srvy_id\n      bts_sh_nm\n    \n  \n  \n    2023-07-04\n30001118\n817756887\n2GUA043C\n    2023-07-04\n30001118\n817756887\nOGUA266B\n    2023-07-04\n30001118\n817756887\n5GUA266B\n    2023-07-04\n30001118\n817756887\nLGUA266I\n    2023-07-04\n30001118\n817756887\nLGTA601C\n  \n  \n  \n\n\n\n\n\nEn la tabla Table 7.2 vemos que el identificador único (número de celular del usuario) se repite, debido a que contamos con datos de perfil"
  },
  {
    "objectID": "eda.html#valores-faltantes",
    "href": "eda.html#valores-faltantes",
    "title": "7  EDA",
    "section": "7.3 Valores faltantes",
    "text": "7.3 Valores faltantes\n\n\nCódigo\nplot_missing(ctl_train, missing_only = TRUE,\n ggtheme = yunkel,\n title = \"Valores Faltantes\",\n geom_label_args = list(label.size = 0.8, size = 8),\n theme_config = list(\n  axis.text = element_text(size = 40)))\n\n\n\n\n\nFigure 7.2: La mayor cantidad de valores perdidos se encuentra en la columna thp_required_lte. Dependiendo de la distribución de los mismos será posible aplicar técnicas de imputación en la fase de preprocesamiento"
  },
  {
    "objectID": "eda.html#resumen-estadístico",
    "href": "eda.html#resumen-estadístico",
    "title": "7  EDA",
    "section": "7.4 Resumen estadístico",
    "text": "7.4 Resumen estadístico\n\n# crear set de datos solo con variables numéricas\nctl_n &lt;- ctl_train |&gt;\n select(where(is.numeric), -c(msisdn_dd, srvy_id))\n\n\n\n\nMostrar Código\nctl_n |&gt; \n resumir() |&gt; \n gt() |&gt; \n # tab_header(\n #  title = md(\"**Resumen Estadístico**\"),\n #    subtitle = md(\"para *features* Numéricos\")\n # ) |&gt; \n gt_theme_538() |&gt; \n cols_align(align = \"center\", columns = where(~ is.numeric(.x))) |&gt; \n fmt_number(columns = where(is.numeric), decimals = 2)\n\n\n\n\n\nTable 7.3:  Resumen estadístico \n  \n    \n    \n      variable\n      media\n      mediana\n      maximo\n      minimo\n      sd\n    \n  \n  \n    thp_required_lte\n0.92\n1.00\n1.00\n0.00\n0.19\n    cll_prctg\n0.16\n0.09\n1.00\n0.00\n0.17\n    rate_prb_dl\n0.65\n0.73\n1.00\n0.00\n0.29\n    rrc_success_rate\n0.90\n1.00\n1.00\n0.00\n0.29\n    erab_success_rate\n0.90\n1.00\n1.00\n0.00\n0.29\n    l_ul_interference_avg\n−102.20\n−113.00\n0.00\n−122.00\n33.28\n    thoughput_dl\n5,660.85\n4,284.99\n87,106.82\n0.00\n5,621.21\n    thpughput_ul\n682.29\n539.11\n5,118.24\n0.00\n592.96\n    corrected_cqi\n9.21\n10.00\n14.00\n0.00\n3.27\n    ra_ta_ue_index1\n0.15\n0.08\n0.87\n0.00\n0.18\n    ra_ta_ue_index2\n0.25\n0.22\n1.00\n0.00\n0.22\n    ra_ta_ue_index3\n0.17\n0.12\n0.94\n0.00\n0.17\n    ra_ta_ue_index4\n0.13\n0.05\n0.99\n0.00\n0.17\n    ra_ta_ue_index5\n0.08\n0.01\n0.99\n0.00\n0.14\n    ra_ta_ue_index6\n0.05\n0.00\n0.96\n0.00\n0.11\n    ra_ta_ue_index7\n0.04\n0.00\n0.94\n0.00\n0.10\n    ra_ta_ue_total\n7,592.41\n5,795.00\n231,144.00\n0.00\n7,842.25\n    volte_erlang\n3.08\n0.89\n41.13\n0.00\n4.52\n    modulation_64qam_ratio\n0.52\n0.56\n0.98\n0.00\n0.24\n    modulation_16qam_ratio\n0.25\n0.26\n0.58\n0.00\n0.12\n    modulation_qpsk_ratio\n0.14\n0.11\n0.85\n0.00\n0.12\n    time_cl\n0.90\n0.97\n1.00\n0.00\n0.16\n    time_lte\n0.92\n0.98\n1.00\n0.00\n0.15\n    avlblty\n1.00\n1.00\n1.00\n0.08\n0.04\n    avlblty_tckt_2hrs\n0.02\n0.00\n1.00\n0.00\n0.08\n    unvlblty_ttl_hrs_prop\n42.29\n3.06\n5,185.17\n0.00\n184.97\n    rain\n132.23\n98.25\n840.00\n0.00\n128.47\n  \n  \n  \n\n\n\n\n\nEn Table 7.3 se observa que hay valores atípicos en algunas observaciones. Los valores mínimos con valor cero para algunas variables ameritan atención."
  },
  {
    "objectID": "eda.html#análisis-univariado",
    "href": "eda.html#análisis-univariado",
    "title": "7  EDA",
    "section": "7.5 Análisis univariado",
    "text": "7.5 Análisis univariado\n\n7.5.1 Variable dependiente\nUno de los primeros pasos del proceso de análisis exploratorios cuando el propósito final es predecir una respuesta es crear visualizaciones que ayuden a dilucidar el conocimiento de la respuesta y luego descubrir relaciones entre los predictores y la respuesta (Kuhn and Johnson 2020).\n\n\nCódigo\nctl_train |&gt; \n barra(diag) +\n theme(legend.position = \"none\") +\n labs(title = \"Clasificación variable politómica\")\n\n\n\n\n\nFigure 7.3: Distribución de la variable dependiente\n\n\n\n\nTal como se muestra en la Figure 7.3 se observa un desbalance en la variable respuesta. Este desequilibrio puede ocasionar que el modelo se sesgue hacia las clases más frecuentes, como “CAPACIDAD” y “PROMOTOR”, lo que podría llevar a un rendimiento deficiente en la clasificación de otras clases. La aplicación de técnicas de remuestreo para balancear las clases será clave en la fase de preprocesamiento.\n\n\n7.5.2 Variables numéricas\nAnalizar la distribución de cada predictor nos puede orientar sobre si necesitamos hacer ingeniería de características mediante transformaciones antes del análisis. (Kuhn and Johnson 2020)\n\ndob &lt;- ctl_n |&gt; \n drop_na()\n\n\n# parámetros para graficar distribuciones\npal &lt;- allcolors[1:ncol(dob)]\nndv &lt;- names(dob)\nnar &lt;- str_to_title(ndv)\n\n\n# crear distribuciones\ndist_predictores &lt;- list(ndv, pal, nar) |&gt;\n  pmap(~ estimar_densidad(df = dob, d = ..1, color = ..2, titulo = ..1))\n\n\n\nMostrar Código\ndist_predictores[1:2] |&gt;\n reduce(.f = `+`) +\n plot_layout(ncol = 2) +\n plot_annotation(title    = \"Distribución predictores numéricos\")\n\n\n\n\n\n\nthp_required_lte: Se observa en la distribución es plausible. Se espera que la mayoría de los usuarios se mantengan un mayor porcentaje de tiempo con el throughput requerido. Sin embargo, el sesgo negativo de esta distribución podría tener un impacto en el rendimiento del modelo.\ncll_prctg: El sesgo positivo es consistente con una distribución exponencial, la cual es comúnmente utilizada para modelar el tiempo entre eventos en un proceso de Poisson, como en este caso.\n\n\n\n\n\n\n\nrate_prb_dl: Sabemos que una alta utilización del PRBs podría indicar una alta demanda de recursos y potencialmente llevar a una degradación del rendimiento de la red. El comportamiento bimodal podría ser un indicio de que hay partes de la red que tienen una utilización de recursos muy baja, es decir, debido a sub-utilización. El comportamiento bimodal es correcto posterior a la entrevista con los SMEs.\nrrc_success_rate: En la distribución vemos que la gran mayoría de usuarios presentan una alta tasa de éxito en cuanto a las conexiones RRC (Radio Resource Control) entre su dispositivo móvil y la red.\n\n\n\n\n\n\n\nerab_success_rate: Mide la tasa de éxito en la configuración, modificación y liberación de los portadores de servicio de acceso radioeléctrico (E-RAB) en una red LTE. Básicamente, muestra qué tan bien la red está asignando recursos a los usuarios para establecer conexiones de datos y voz. La distribución es la esperada con un sesgo positivo muy pronunciado, lo cual es un indicador de que la mayor parte del tiempo este indicador se encuentra en un rango saludable.\nl_ul_interferance_avg: Representa la interferencia promedio en el enlace ascendente (UL) de una celda LTE. Se mide en decibelios-milivatios (dBm) y sirve para evaluar el nivel de ruido o interferencia que podría estar afectando la calidad del enlace ascendente. Altos niveles de interferencia pueden llevar a una degradación de la calidad de la llamada, reducir el rendimiento del enlace de datos y afectar negativamente la experiencia general del usuario. Un número menor (más negativo) generalmente indica menos interferencia, lo cual es positivo para el rendimiento de la red. Se aprecia un comportamiento bimodal lo que podría ser un indicio de celdas problemas muy serios o que están desconfiguradas. Se debe investigar si es un error en los datos o si son casos particulares. Los valores atípicos pueden afectar más la transmisión en los escenarios donde esta última va por microondas.\n\n\n\n\n\n\n\nthroughput_dl: Mide la velocidad de descarga por Unidad de Equipo de Usuario en una red celular, generalmente en Mbps. Según la gráfica, el downlink se ubica en su mayoría arriba de los 25Mbps, lo cual es esperado. Lo que es necesario analizar es el throughput_dl menor a 2.7 Mbps. Una gran parte de los usuarios se encuentran por debajo de este umbral.\nthroughput_ul: Mide la velocidad de transmisión de datos del dispositivo móvil a la estación base, generalmente también en Mbps. Es normal observar valores más bajos en el uplink que en el downlink. El sesgo positivo también es adecuado.\n\n\n\n\n\n\n\ncorrected_cqi: Evalúa la calidad de una celda en una red móvil. Este índice toma en cuenta varios factores como la potencia de la señal, el nivel de interferencia y otros parámetros clave para dar un indicador comprensivo de cómo está funcionando una celda en particular. Aunque los detalles pueden variar según el fabricante y la implementación, en esencia, mide qué tan bien una celda puede manejar el tráfico y proporcionar un servicio de alta calidad a los usuarios. Como política, el departamento de QA definió un umbral crítico de 7, significando que todo lo que esté por debajo de dicho umbral es malo. Debido a la naturaleza discreta de la distribución de estos valores, observamos que la superposición de densidad aparenta multimodalidad, sin embargo, no es así. Las celdas con valores atípicos inferiores a 1 es porque se encuentran en tunning, normalmente porque empiezan con número o porque aun no le han cambiado la etiqueta.\nra_ta_ue_index1: Es una métrica que, en función de distintos índices, indica tanto la distancia aproximada entre la estación base y el dispositivo móvil, como la cantidad de conexiones realizadas a esas distancias específicas. Se utiliza para evaluar y optimizar la cobertura y la capacidad de la red. El sesgo positivo en este tipo de métrica es esperado en vista de que depende de la cantidad de muestras de dicha celda.\n\n\n\n\n\n\nTA 2 está a un radio de 500 mts\n\n\n\n\n\n\n\n\n\n\n\nra_ta_ue_index2-7: Al igual que con ra_ta_ue_index1, el timing advanced del 2 al 7 representan la cantidad de conexiones realizadas a una determinada distancia. Lo importante es ver que existen más muestras en los índices más próximos a 1 y deberían existir pocas conexiones en los índices más altos. Muchas conexiones en índices más altos indicaría que muchos usuarios se están conectando a las celdas desde lugares muy lejanos o hay otros problemas como obstáculos u optimización.\n\n\n\n\n\n\n\nra_ta_ue_total: Cantidad total de conexiones de datos o llamadas. Pueden ser del mismo terminal. Pocas celdas tendran muestras muy elevadas.\nvolte_erlang: Mide el volumen de tráfico VoLTE (Voice over LTE) en la red. Se expresa en “erlangs”, que es una unidad de medida de carga de tráfico telefónico. Si cualquier otra banda supera 1/3 del tráfico VoLTE de la banda 850, se considera una situación crítica. Es necesario tener visibilidad del tráfico VoLTE en todas las bandas utilizadas para VoLTE, no solo la 850.\n\n\n\n\n\n\n\nmodulation_64qam_ratio: Se define como el porcentaje de tiempo en que la transferencia de datos usa 64QAM, que es una modulación de alta eficiencia. Esta modulación permite transmitir más bits de información y usa menos bits para la corrección de errores, lo que la hace más eficiente pero también más susceptible a problemas de calidad de señal. Como se aprecia en el histograma, hay un comportamiento bimodal que puede indicar que en ciertas celadas o bien ubicaciones geográficas, hay pocos usuarios utilizando este tipo de modulación de mayor capacidad. Dejando de lado el valor atípico, se observa que la distribución es bastante normal.\n\nSi la última letra termina en UWXYZ entonces la celdas podría estar apagada Podríamos excluir con base a la tabla de Kenny aquellas celdas que no empiecen con alguno de los prefijos que maneja Kenny. Kenny nos compartirá la tabla. Si aparece en cero en todas las modulaciones, podría ser que no tiene activado los contadores. - No hay modulación para 3G, solo para LTE - Probar una receta filtrando todo los 3G y otra con todos los 3G y LTE.\n\nmodulation_16qam_ratio: Representa el porcentaje de tiempo que la red está utilizando la modulación 16-Quadrature Amplitude Modulation (16QAM) para la transferencia de datos. Esta modulación es intermedia en términos de eficiencia y robustez, permitiendo un balance entre la cantidad de datos transmitidos y la corrección de errores. Es menos eficiente que 64QAM pero más robusta contra errores y condiciones de señal no ideales. La distribución parece normal y se observa, al igual que con 64QAM, un comportamiento bimodal que podría ser indicativo de que hay presente otra población en este tipo de modulación.\n\n\n\n\n\n\n\nmodulation_qpsk_ratio: Representa el porcentaje de tiempo en que la red utiliza la modulación Quadrature Phase Shift Keying (QPSK) para la transferencia de datos. QPSK es una forma de modulación que es más robusta en ambientes con condiciones de señal no ideales, como ruido o interferencias. Sin embargo, es menos eficiente para la transmisión de datos en comparación con 16QAM o 64QAM. A diferencia de los otros dos tipos de modulación, la distribución de esta modulación es positiva, similar a una distribución exponencial. Podría hacer sentido si el objetivo del departamento de QA es utilizar este tipo de modulación como último recurso en caso de que no se tengan las condiciones adecuadas en términos de interferencia o cobertura.\ntime_cl: Es una medida fabricada que toma en cuenta la utilización de PRBs, el CQI, y la velocidad target de la celda, para determinar el grado de cumplimiento de esa velocidad. Porcentaje de tiempo en buen cell_load, va tanto 3G como LTE. El sesgo negativo es correcto en vista de que se espera que la mayor parte de las conexiones se encuentren con un buen cell_load.\n\n\n\n\n\n\n\ntime_lte: Porcentaje de tiempo que permanece conectado a la tecnología LTE. Entre más tiempo permanece un usuario conectado a la red LTE, podemos decir que es bueno. Abajo del 80% podría indicar que las celdas tienen un alto cell_load lo que indicaría que el terminal hizo el cambio automático a 3G. Navegar en 3G por lo general se traduce en una experiencia más pobre. El sesgo de la distribución es plausible.\navlblty: Porcentaje de tiempo de navegación sin falla. Esto aplica por usuario y representa un medida de que tanto un usuario navegó la cantidad de Mb esperados con base a su mediana de consumo. La distribución con sesgo negativo es consistente con la definición de la métrica.\n\n\n\n\n\n\n-avlblty_tckt_2hrs y unvlbty_ttl_hrs_prop: Son métricas complementarias a la de disponibilidad y representan partes de la disponibilidad. Su sesgo es opuesto.\nComo se señaló en la sección Section 7.2, los datos de perfil demandan un preprocesamiento especializado. Los modelos seleccionados deben ser robustos ante este tipo de datos y la presencia de valores atípicos. Por esta razón, es recomendable considerar modelos basados en árboles, que son inherentemente más tolerantes a estas características. Además, se explorarán diversas transformaciones de las variables para evaluar y comparar su impacto en el rendimiento del modelo.\n\n\n7.5.3 Variables categóricas\n\nctl_c &lt;- ctl_train |&gt;\n select(where(is.character), -diag) \n\n\n\nCódigo\nctl_c |&gt;\n inspect_cat() |&gt; \n show_plot(high_cardinality = 4, col_palette = 1)\n\n\n\n\n\nFigure 7.4: Análisis de cardinalidad de variables categóricas\n\n\n\n\n\n\nCódigo\nplot_bar(\n data    = ctl_c, \n ggtheme = yunkel, \n theme_config = list(strip.text = element_text(size = 22)))\n#&gt; 3 columns ignored with more than 50 categories.\n#&gt; cty_nm: 296 categories\n#&gt; bts_sh_nm: 11281 categories\n#&gt; twr: 3642 categories\n\n\n\n\n\nFigure 7.5: Conteo de variables categóricas\n\n\n\n\n\n\nCódigo\nctl_c |&gt; \n select(bts_sh_nm) |&gt; \n mutate(celda = fct_lump(bts_sh_nm, n = 10, other_level = \"OTRAS\")) |&gt; \n count(celda, sort = TRUE) |&gt; \n filter(celda != \"OTRAS\") |&gt; \n mutate(celda = fct_reorder(celda, n, .desc = FALSE)) |&gt; \n ggplot(aes(y = celda, x = n)) +\n geom_col() +\n labs(title = \"Top celdas más concurridas\")\n\n\n\n\n\nFigure 7.6: Top de celdas recurrentes por usuarios"
  },
  {
    "objectID": "eda.html#análisis-bivariado",
    "href": "eda.html#análisis-bivariado",
    "title": "7  EDA",
    "section": "7.6 Análisis bivariado",
    "text": "7.6 Análisis bivariado\n\n7.6.1 Dependiente vs numéricas\n\n7.6.1.1 Gráficos de confianza\nDebido al desbalance de clases presente en la variable respuesta, será necesario reflejar claramente el grado de incertidumbre que esto ocasiona. Si una clase tiene más observaciones que otra entonces la comparación no sería justa y la variabilidad podría tener que ver con esto más que con la variabilidad inherente que intentamos capturar. Para hacer esto, primero recordemos que una estimación de intervalo describe un rango de valores dentro del cual es posible que esté un parámetro de la población y un intervalo de confianza es la probabilidad que asociamos con una estimación de intervalo (Levin and Rubin 1998).\nEn este sentido, los gráficos de confianza son esenciales para entender no solo la relación de la variable categórica diag con las métricas numéricas, sino también para capturar el grado de incertidumbre asociado con estas métricas. Estos gráficos nos permiten ir más allá de las simples medias y observar cómo la variabilidad en los datos afecta nuestras conclusiones.\nLos gráficos de confianza nos permiten ver cómo cada métrica, se relaciona directamente con las categorías de diag. Por ejemplo, si observamos que los intervalos de confianza para thp_required_lte son significativamente bajos en la categoría “CAPACIDAD”, podemos inferir con cierto grado de confianza que un thp_required_lte bajo generalmente indica un problema de capacidad.\nEl intervalo da una idea de dónde podrían caer las verdaderas medias de thp_required_lte para cada categoría si tuvieras acceso a toda la población, en lugar de solo una muestra.\n\n\n\n\n\n\n¿Por qué no solo usar únicamente boxplots?\n\n\n\nAunque los boxplots ofrecen una visión más completa de la distribución de los datos, no proporcionan el mismo nivel de detalle sobre la incertidumbre en torno a la media que los gráficos de confianza. Usar ambos proporciona una visión más completa de los datos. Los gráficos de confianza dan detalles sobre la media y su incertidumbre, mientras que los boxplots muestran la distribución completa.\n\n\n\n# Función para calcular la media y el intervalo de confianza\nmean_ci &lt;- function(df, metrica, conf.level = 0.95) {\n x  &lt;- df[[metrica]][!is.na(df[[metrica]])]\n n  &lt;- length(x)\n m  &lt;- mean(x)\n se &lt;- sd(x) / sqrt(n)\n ci &lt;- t.test(x)$conf.int\n data.frame(media = m, lower = ci[1], upper = ci[2])\n}\n\n\n# Función para crear un dataframe con los intervalos por cada métrica\ncalcular_ci &lt;- function(kpi) {\n ctl_train |&gt; \n group_by(diag) %&gt;%\n do(mean_ci(., kpi)) %&gt;%\n ungroup() %&gt;%\n arrange(media)\n}\n\n\n# Guardar las métricas que vamos a comparar\nnetwork_metrics &lt;- names(ctl_n)\n\n\n# Crear lista de dataframes con intervalos de confianza\nlista_ci &lt;- network_metrics |&gt; \n map(~ calcular_ci(kpi = .x)) |&gt; \n set_names(network_metrics)\n\n\n# Crear una lista con las gráficas de cada métrica\nanalisis_bivariado &lt;- lista_ci |&gt; \n map2(.y = network_metrics, ~ ggplot(.x, aes(x = diag, y = media)) +\n geom_point() +\n geom_errorbar(aes(ymin = lower, ymax = upper), width = .1) +\n theme(axis.text = element_text(size = 8)) +\n xlab(\"Diagnóstico\") +\n labs(title = .y) +\n drako) |&gt; \n discard_at(\"ra_ta_ue_total\")\n\n\n\n\n\n\nFigure 7.7: Porcentaje de tiempo que mantiene el throughput requerido en LTE\n\n\n\n\nTal como se ilustra en la figura Figure 7.7 el intervalo de confianza para la categoría “CAPACIDAD” va de aproximadamente 0.85 a 0.861. Esto significa que, con un 95% de confianza, se puede decir que la la verdadera media de thp_required_lte se encuentra en este rango.\n\n\n\n\n\nFigure 7.8: Porcentaje de tiempo que el usuario estuvo conectado a la celda.\n\n\n\n\nLos resultados observados en la Figure 7.8 son consistentes con las expectativas. Vemos que la categoría “PROMOTOR” muestra un alto porcentaje de tiempo de conexión a la red, lo cual es congruente con la naturaleza de esta categoría. Los intervalos altos pueden deberse a una alta variabilidad en los datos.\n\n\n\n\n\nFigure 7.9: Porcentaje de bloques físicos utilizados para transmitir datos desde la RBS hacia los terminales. Una alta tasa de utilización de PRB podría generar problemas de capacidad.\n\n\n\n\nEsta métrica es utilizada principalmente por el equipo CTL para determinar problemas de capacidad en la red LTE. Vemos en la Figure 7.9 que hay una diferencia grande entre esta medición y el resto de categorías, es decir, niveles altos de rate-prb-dl se asocian con problemas de capacidad en la celda.\n\n\n\n\n\nFigure 7.10: Eficiencia en el establecimiento de una conexión RRC\n\n\n\n\nSabemos que una métrica puede impactar múltiples categorías. El equipo CTL utiliza esta métrica principalmente para determinar problemas de optimización, sin embargo, también puede asociarse a problemas de cobertura. La explicación es que si la tasa de éxito de RRC es baja, esto podría deberse a áreas con señal débil o a problemas con la infraestructura de la red.\n\n\n\n\n\nFigure 7.11: Tasa de éxito en la configuración, liberación y modficación de portadoras de servicio de accesso radioeléctrico (E-RAB)\n\n\n\n\nAl igual que con la métrica anterior, esta métrica puede generar varias etiquetas si se combina con otras. De manera aislada y directa parece estar más relacionada a problemas con cobertura.\n\n\n\n\n\nFigure 7.12: Interferencia promedio del enlace ascendente (uplink) de la celda\n\n\n\n\nEn la Figure 7.12 se aprecia que valores mayores de interferencia podrían ocasionar problemas de cobertura. Esta métrica en particular puede interactuar con muchas otras métricas para determinar otro tipos de problemas en la red como por ejemplo optimización.\n\n\n\n\n\nFigure 7.13: Velocidad de descarga por Unidad de Equipo de Usuario en una red celular, generalmente en Mbps.\n\n\n\n\nCTL describe esta métrica principalmente en términos de capacidad, sin embargo, se observa que la estimación puntual de la media para cobertura se encuentra muy cercana. En este caso, amerita evaluar si esta diferencia es significativa.\n\n\n\n\n\nFigure 7.14: ANOVA entre-sujetos\n\n\n\n\nEn la parte superior de la Figure 7.14 vemos el resultado de la prueba estadística de Fisher. El p-valor indica que si hay diferencias significativas con un tamaño de efecto de \\(\\widehat{\\omega_{p}^{2}} = 0.09\\). Este tamaño de efecto se puede medir como 9% lo cual es bajo. Se ve en las comparaciones por pares que capacidad y cobertura presentan diferencias estadísticamente significativas.\n\n\n\n\n\nFigure 7.15: Velocidad de transmisión de datos del dispositivo móvil a la estación base, generalmente también en Mbps.\n\n\n\n\nEl equipo CTL no utiliza esta métrica como parte de su proceso de etiquetado, sin embargo, la hemos colocado ya que puede ser útil en algunos contextos.\n\n\n\n\n\nFigure 7.16: Índice de calidad general de la celda\n\n\n\n\nLa Figure 7.16 muestra los diferentes índices para cada una de las categorías. Todo lo que esté por arriba de 7 se considera bueno. Aunque el equipo CTL indica que esta métrica tiene más utilidad para determinar problemas de optimización, lo que destaca a simple vista es que valores bajos de esta métrica se asocian más con problemas de cobertura.\n\n\n\n\n\nFigure 7.17: Cantidad de conexiones realizadas a distancias específicas dadas por el índice.\n\n\n\n\n\n\n\nFigure 7.18: Cantidad de conexiones realizadas a distancias específicas dadas por el índice.\n\n\n\n\n\n\n\nFigure 7.19: Cantidad de conexiones realizadas a distancias específicas dadas por el índice.\n\n\n\n\n\n\n\nFigure 7.20: Cantidad de conexiones realizadas a distancias específicas dadas por el índice.\n\n\n\n\n\n\n\nFigure 7.21: Cantidad de conexiones realizadas a distancias específicas dadas por el índice.\n\n\n\n\n\n\n\nFigure 7.22: Cantidad de conexiones realizadas a distancias específicas dadas por el índice.\n\n\n\n\n\n\n\nFigure 7.23: Cantidad de conexiones realizadas a distancias específicas dadas por el índice.\n\n\n\n\nLo observado es consistente con lo esperado. En el caso del índice 1, un porcentaje bajo de conexiones en este índice podría indicar que el resto de muestras se están obteniendo de índices más lejanos. Se observa que a partir del índice 4 el porcentaje empieza a ser diferente entre capacidad y cobertura. En el índice 5 cobertura y capacidad tienen un porcentaje cercano, pero siempre cobertura es menor, hasta que finalmente en índice 6 ciertas conexiones se pueden etiquetar tanto como problemas de capacidad como de cobertura.\n\n\n\n\n\nFigure 7.24: Índice de calidad general de la celda\n\n\n\n\n\n\n\nFigure 7.25: Índice de calidad general de la celda\n\n\n\n\n\n\n\n\n\nFigure 7.26: Índice de calidad general de la celda\n\n\n\n\n\n\n\nFigure 7.27: Índice de calidad general de la celda\n\n\n\n\n\n\n\n\n\nFigure 7.28: Índice de calidad general de la celda\n\n\n\n\n\n\n\nFigure 7.29: Índice de calidad general de la celda\n\n\n\n\n\n\n\n\n\nFigure 7.30: Índice de calidad general de la celda\n\n\n\n\n\n\n\nFigure 7.31: Índice de calidad general de la celda\n\n\n\n\n\n\n\n\n\nFigure 7.32: Índice de calidad general de la celda\n\n\n\n\n\n\n\nFigure 7.33: Índice de calidad general de la celda\n\n\n\n\n\n\n7.6.1.2 Variabilidad y rango\nDebido a que\n\nctl_normalized &lt;- ctl_train |&gt;\n select(where(is.numeric), \n  -c(msisdn_dd, srvy_id), diag) |&gt; \n recipe(diag ~ ., data = _) |&gt; \n step_best_normalize(all_predictors(), -all_nominal())  |&gt; \n ver()\n\n\nctl_normalized |&gt; \n select(-c(avlblty, avlblty_tckt_2hrs)) |&gt; \n plot_boxplot(\n  by = \"diag\", \n  ncol = 3,\n  geom_boxplot_args = list(\"outlier.color\" = \"red\"), \n  ggtheme = drako, \n  theme_config = list(strip.text = element_text(size = 30)))    \n\n\n\n\nFigure 7.34: Análisis de variabilidad, rango y atípicos\n\n\n\n\n\n\n\nFigure 7.35: Análisis de variabilidad, rango y atípicos\n\n\n\n\n\n\n\nFigure 7.36: Análisis de variabilidad, rango y atípicos\n\n\n\n\nUsamos el paquete {bestNormalize} para transformar los datos y mejorar la visualización de los boxplots. Aunque los gráficos de confianza son más detallados, los boxplots también muestran variaciones importantes dentro de cada categoría. El rango intercuartil (IQR) nos indica que hay más variabilidad en ciertos features. En particular, las variables corrected_cqi, interferencia y time_cl muestran menos variación. Como se discutió en la sección Section 7.5.2, la variable 64QAM sigue una distribución cercana a la normal. Para tratar los valores atípicos podemos considerar el aplicar una transformación llamada spatial sign (ver Kuhn and Johnson 2020) y (Kuhn and Johnson 2013) o bien usar modelos robustos a valores atípicos.\n\n\n\n7.6.2 Analizar interacciones\nSegún los SMEs entrevistados, la categoría optimización por lo general depende de un par de variables, es decir, que esta categoría podría ser el resultado de interacciones entre variables. Las métricas que principalmente se utilizan para determinar esto son:\n\nerab_success_rate\nrrc_success_rate\ncorrected_cqi\nl_ul_interference_avg\n\n\nmodelo &lt;- lm(\n rrc_success_rate ~ l_ul_interference_avg * diag, \n data = ctl_train)\n\n\ninteract_plot(modelo, pred = l_ul_interference_avg, modx = diag)\n\n\n\n\nDado que las lineas son casi paralelas se puede concluir que no hay una interacción entre los factores\nLa interacción entre factores se puede observar cuando las líneas del diagrama se cruzan o tienen pendientes muy diferentes lo cual indica que la variable respuesta se comporta diferente al variar un factor dependiendo del valor del otro factor.\n\n\n7.6.3 Dependiente vs categóricas\nUtilizar ambos indicadores para todas las regiones. Va a depender si el CVE al que le estamos apuntando es urbano (time_lte) o rural (time_cl).\n\n# Seleccionar predictores de tipo factor y dejar top-10 para ciudad\nctl_fc &lt;- ctl_train |&gt; \n select(where(is.character), -bts_sh_nm, time_cl) |&gt; \n mutate(ciudad = fct_lump(cty_nm, n = 10, other_level = \"OTRO\")) |&gt; \n select(-cty_nm) |&gt; \n drop_na()\n\n\n# Calcular combinaciones para tree-maps\nnx &lt;- length(names(ctl_fc |&gt; select(-time_cl)))\nchoose(nx, 2)\n#&gt; [1] 15\n\n\n# Crear combinaciones\ncomb &lt;- combinations(nx, 2, names(ctl_fc |&gt; select(-time_cl)), repeats = F)\n\n\n# Crear objeto con combinaciones\nnm &lt;- map2_chr(comb[, 1], comb[, 2], ~ str_c(.x, .y, sep = \"_\"))\n\n\n# Función para dejar únicamente las combinaciones con diagnóstico\ntiene_diag &lt;- function(x) str_detect(x, pattern = \"diag\")\n\n\n# Generar mosaicos\nlista_mosaicos &lt;- map2(\n .x = comb[, 1],\n .y = comb[, 2], \n ~ graficar_mosaicos(\n  df = ctl_fc,\n  f1 = .x,\n  f2 = .y,\n  ra = 0.3,\n  leyenda = TRUE)) |&gt;\n set_names(nm) |&gt; \n keep_at(tiene_diag)\n\n\n\n\n\n\nFigure 7.37: Mayor time-cl por municipio\n\n\n\n\n\n\n\n\n\nFigure 7.38: Mayor time-cl por departamento\n\n\n\n\n\n\n\n\n\nFigure 7.39: Mayor time-cl por región comercial\n\n\n\n\n\n\n\n\n\nFigure 7.40: Mayor time-cl por región rf-planning\n\n\n\n\n\n\n7.6.4 Análisis de correlación\nSe debe realizar la inspección de las correlaciones que se encuentren arriba de 0.75 en valor absoluto. Este umbral es sugerido por algunos autores (Kuhn and Johnson 2013, pag 87).\n\n# La correlación de Spearman es más sólida para los valores\n# atípicos que la correlación de Pearson.\ncorm &lt;- ctl_n |&gt;\n correlate(\n  use    = \"pairwise.complete.obs\", \n  method = \"spearman\", \n  quiet  = TRUE)\n\n\n\nMostrar Código\ncorm |&gt; \n rearrange() |&gt; \n shave() |&gt; \n rplot(colours = c(\"red\", \"green\")) +\n labs(title = \"Matriz de correlación\", \n      subtitle = \"Correlaciones mayores a 0.75\") +\n yunkel +\n theme(axis.text.y = element_text(size = 14),\n       axis.text.x = element_text(size = 16, angle = 45, hjust = 1))\n\n\n\n\n\nFigure 7.41: Análisis de correlación\n\n\n\n\n\nmatriz_reducida &lt;- corm |&gt; \n rearrange() |&gt; \n shave() |&gt; \n stretch(na.rm = TRUE) |&gt; \n filter(abs(r) &gt;= .75)\n\n\n\nMostrar Código\nmatriz_reducida |&gt; \n arrange(r) |&gt; \n gt() |&gt; \n gt_theme_538() |&gt; \n tab_header(\n  title = html(\"&lt;p style='color:#25a7f0;'&gt;&lt;strong&gt;Correlaciones altas&lt;/strong&gt;&lt;/p&gt;\"),\n    subtitle = md(\"Mayores a 0.75\")\n  ) |&gt; \n data_color(\n    columns = r,\n    method = \"numeric\",\n    palette = \"RdYlGn\", \n    reverse = TRUE\n  ) |&gt; \n tab_style(\n    style = list(cell_text(align = \"center\"), v_align = \"top\"),\n    locations = cells_column_labels(columns = everything())\n )\n\n\n\n\n\nTable 7.4:  high-r \n  \n    \n      Correlaciones altas\n    \n    \n      Mayores a 0.75\n    \n    \n      x\n      y\n      r\n    \n  \n  \n    ra_ta_ue_index5\nra_ta_ue_index6\n0.7701307\n    rrc_success_rate\nthpughput_ul\n0.7719502\n    erab_success_rate\nthpughput_ul\n0.7860535\n    modulation_16qam_ratio\nmodulation_qpsk_ratio\n0.8370045\n    rrc_success_rate\nerab_success_rate\n0.9406787\n    modulation_64qam_ratio\ncorrected_cqi\n0.9813649\n  \n  \n  \n\n\n\n\n\nLa correlación de Pearson es mayor que la de Spearman, lo que podría significar que existan correlaciones no lineales entre los predictores y la variable objetivo. Las interacciones complejas entre predictores es parte de lo esperado dado el contexto brindado por los SMEs.\n\n\n7.6.5 Mutual information\n\n\n\n\nKuhn, Max, and Kjell Johnson. 2013. Applied Predictive Modeling. New York: Springer.\n\n\n———. 2020. Feature Engineering and Selection: A Practical Approach for Predictive Models. Chapman & Hall/CRC Data Science Series. Boca Raton London New York: CRC Press, Taylor & Francis Group.\n\n\nLevin, Richard I., and David S. Rubin. 1998. Statistics for Management. 7th ed. Upper Saddle River, N.J: Prentice Hall."
  },
  {
    "objectID": "modeling.html",
    "href": "modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "El framework a utilizar para el modelado será tidymodels. En tidymodels el preprocesamiento y el modelado están integrados a través de algo llamado workflow, el cual tiene similitudes con los pipelines de Python.\nEsta integración de preprocesamiento permite que todo el feature-engineering se realice en algo llamado receta, a lo que después se le pueden pasar las especificaciones de modelos que sean necesarias.\n\n\n\nModelado y preprocesamiento"
  },
  {
    "objectID": "cross-validation.html",
    "href": "cross-validation.html",
    "title": "8  Cross-validation",
    "section": "",
    "text": "La validación cruzada de grupo V crea divisiones de los datos en función de alguna variable de agrupación (que puede tener más de una fila asociada). La función puede crear tantas divisiones como valores únicos de la variable de agrupación o puede crear un conjunto más pequeño de divisiones donde más de un grupo queda fuera a la vez. Un uso común de este tipo de remuestreo es cuando se tienen medidas repetidas del mismo tema.\n\n# 31.22 seg\ntictoc::tic()\nctl_folds &lt;- group_vfold_cv(\n1 data    = ctl_train,\n2 group   = \"msisdn_dd\",\n3 v       = 10,\n4 balance = \"observations\",\n5 strata  = \"diag\")\ntictoc::toc()\n#&gt; 20.11 sec elapsed\n\n\n1\n\nUsar el conjunto de datos de entrenamiento.\n\n2\n\nSe define la unidad experimental, que en este caso es el usuario como la variable de agrupación. El objetivo es garantizar que todas las observaciones para un usuario específico estén en el mismo fold.\n\n3\n\nNúmero de particiones (pliegos). Es el número de valores únicos en la variable de agrupación. Debido a que tenemos un conjunto grande de observaciones, elegiremos v = 10.\n\n4\n\nIntenta equilibrar el número de observaciones en cada fold. La función group_vfold_cv() intentará asignar aproximadamente el mismo número de observaciones a cada fold, lo que podría ayudar a mitigar el impacto del desbalanceo en la validación cruzada.\n\n5\n\nEstratificar es apropiado si se quiere asegurar que cada fold tenga una distribución similar de la variable de diagnóstico.\n\n\n\n\n\nctl_folds\n#&gt; # Group 10-fold cross-validation \n#&gt; # A tibble: 10 × 2\n#&gt;    splits               id        \n#&gt;    &lt;list&gt;               &lt;chr&gt;     \n#&gt;  1 &lt;split [13368/1482]&gt; Resample01\n#&gt;  2 &lt;split [13368/1482]&gt; Resample02\n#&gt;  3 &lt;split [13363/1487]&gt; Resample03\n#&gt;  4 &lt;split [13359/1491]&gt; Resample04\n#&gt;  5 &lt;split [13368/1482]&gt; Resample05\n#&gt;  6 &lt;split [13368/1482]&gt; Resample06\n#&gt;  7 &lt;split [13368/1482]&gt; Resample07\n#&gt;  8 &lt;split [13368/1482]&gt; Resample08\n#&gt;  9 &lt;split [13356/1494]&gt; Resample09\n#&gt; 10 &lt;split [13364/1486]&gt; Resample10"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "13  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Géron, Aurélien. 2017. Hands-on Machine Learning with\nScikit-Learn and TensorFlow:\nConcepts, Tools, and Techniques to Build Intelligent Systems. First\nedition. Beijing ; Boston: O’Reilly Media.\n\n\nKuhn, Max, and Kjell Johnson. 2013. Applied Predictive\nModeling. New York: Springer.\n\n\n———. 2020. Feature Engineering and Selection: A Practical Approach\nfor Predictive Models. Chapman &\nHall/CRC Data Science Series. Boca Raton\nLondon New York: CRC Press, Taylor & Francis Group.\n\n\nLevin, Richard I., and David S. Rubin. 1998. Statistics for\nManagement. 7th ed. Upper Saddle River, N.J: Prentice Hall."
  }
]