# Preprocessing {#sec-preprocessing}

```{r}
#| echo: false
source("_common.R")
source("_functions.R")
source("_load.R")
```

```{r}
#| echo: false
tablero_ctl <- board_folder(path = "tablero_ctl")
```

```{r}
#| echo: false
ctl_split <- pin_read(board = tablero_ctl, name = "ctl_split")
ctl_folds <- pin_read(board = tablero_ctl, name = "ctl_folds")
ctl_train <- training(ctl_split)
```


Una variedad de opciones y pasos adicionales a menudo ocurren antes de ajustar
los modelos.

La ingeniería de características implica reformatear los valores de los
predictores para que un modelo los utilice de manera más efectiva. Esto incluye
transformaciones y codificaciones que resalten las características importantes
de los datos. Por ejemplo, se podría crear un nuevo predictor a partir de la
relación entre dos predictores existentes. La elección de cómo codificar los
datos, ya sea numéricamente o categóricamente, también es crucial.

Otros métodos de preprocesamiento incluyen la reducción de la correlación entre
predictores mediante la extracción de características o la eliminación de
algunos predictores, la imputación de valores faltantes y la transformación de
predictores sesgados para hacer que su distribución sea simétrica. Además,
algunos modelos requieren que los predictores numéricos estén centrados y
escalados para evitar sesgos en las métricas de distancia. En resumen, la
ingeniería de características y el preprocesamiento de datos son pasos
esenciales para mejorar el rendimiento del modelo.

```{r}
mset <- metric_set(precision, recall, f_meas)

# definir race control para búsqueda de hiperparámetros
race_ctrl <- control_race(
 save_pred     = TRUE,
 parallel_over = "everything",
 save_workflow = TRUE)
```

## Recetas

```{r}
tic()
# Feature engineering
sencillo <- recipe(diag ~  ., data = ctl_train) |> 
  update_role(msisdn_dd, new_role = "user_id") |> 
  step_nzv(all_numeric_predictors()) |> 
  step_date(
   fecha_15dias, 
   features = c("dow", "month", "quarter", "semester"), 
   label = FALSE, 
   keep_original_cols = FALSE) |> 
  step_impute_median(all_numeric_predictors()) |> 
  step_normalize(all_numeric_predictors()) |> 
  step_rm(fct_srvy_dt, 
          bts_sh_nm, 
          trrtry_tf_nm, 
          where(is.ordered)) |> 
  step_rm(all_nominal_predictors()) |> 
  step_smote(diag, skip = TRUE)


# Model Spec
decision_tree_spec <- decision_tree(
  tree_depth      = tune(), 
  min_n           = tune(), 
  cost_complexity = tune()) %>%
 set_engine("rpart") %>%
 set_mode("classification")


ctl_set <- workflow_set(
 preproc = list(receta_simple  = sencillo), 
 models  = list(
  # multinom_reg_glmnet = multinom_reg_glmnet_spec,
  # multinom_reg_brulee = multinom_reg_brulee_spec
  
  # mlp_keras = mlp_keras_spec,
  # multinom_reg_keras = multinom_reg_keras_spec,
  # nnet = nnet_spec,
  # svm_poly_kernlab = svm_poly_kernlab_spec
  
  rpart      = decision_tree_spec
  # bag_tree_rpart = bag_tree_rpart_spec,
  # xgboost    = boost_tree_xgboost_spec
  # random_forest = rand_forest_ranger_spec
  # multinom_reg_nnet = multinom_reg_nnet_spec
 )
) 

cl <- makePSOCKcluster(10)
registerDoParallel(cl)


tune_res <- ctl_set %>% 
 workflow_map(
 fn        = "tune_race_anova", 
 verbose   = TRUE,
 resamples = ctl_folds,
 control   = race_ctrl,
 seed      = 2023,
 metrics   = mset,
 grid      = 10)


stopCluster(cl)
unregister()


tune_res %>%
 rank_results(select_best = TRUE, rank_metric = "f_meas") %>% 
 select(modelo = wflow_id, .metric, mean, rank) %>% 
 pivot_wider(names_from = .metric, values_from = mean)

toc()
```





